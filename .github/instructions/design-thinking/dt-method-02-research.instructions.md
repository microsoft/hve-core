---
description: 'Method 2 Design Research coaching knowledge: interview techniques, research planning, environmental observation, and insight extraction patterns'
applyTo: '**/.copilot-tracking/dt/**/method-02*'
---

# DT Method 02: Design Research

Systematic discovery of end-user needs through direct engagement (interviews, observations, surveys) transforms abstract business problems into concrete user insights. Skipping this method results in building solutions that stakeholders want but users do not need.

## Purpose

Bridge the gap between stakeholder assumptions and actual user experiences by discovering what problems users really face in their work environment.

## Sub-Method Phases

Method 2 organizes into three sequential phases. Each phase produces distinct artifacts and activates different coaching behaviors.

### Phase 1: Research Planning

Translate Method 1 scope findings into a structured research strategy. Determine which users to engage, what methods to use, and how to sequence research activities within available resources.

Activities: research objective definition, user target prioritization by tier, method selection (interviews, observation, surveys), timeline and logistics planning, compliance and safety protocol identification.

Exit criteria: a research plan artifact exists with prioritized objectives, tiered user targets, selected methods, and a timeline.

### Phase 2: Research Execution

Conduct interviews, observations, and surveys following the research plan. Adapt questions and focus areas based on emerging discoveries. Capture raw data including direct quotes, environmental measurements, and workflow observations.

Activities: live interview coaching, environmental observation, workaround investigation, constraint discovery, cross-interview pattern flagging.

Exit criteria: raw interview notes and observation logs exist for each research session with direct quotes and specific observations.

### Phase 3: Research Documentation

Organize raw findings into structured artifacts ready for Method 3 synthesis. Anchor every insight to direct evidence. Identify patterns and flag contradictions to initial assumptions.

Activities: pattern extraction from raw notes, evidence anchoring to quotes and observations, assumption validation against Method 1 hypotheses, constraint cataloging with design implications.

Exit criteria: a findings document exists with evidence-backed patterns, environmental constraint documentation, and assumption validation results.

## Coaching Hats

Two specialized coaching hats provide focused expertise within Method 2. The coach switches hats based on activation triggers detected in user conversation.

### Research Designer

Strategic research planning expertise. Guides study design, user prioritization, and resource optimization.

Activation triggers:

* User asks how to structure or plan their research approach.
* User mentions resource constraints, timelines, or access challenges.
* User needs to translate Method 1 findings into research targets.
* User asks which users to prioritize or what methods to use.
* Conversation involves research protocol development or study design decisions.

Coaching focus:

* Constraint Discovery Matrix: systematically plan exploration across physical, technical, organizational, and workflow constraint categories.
* Assumption Testing Protocol: design specific observations, interview questions, and validation approaches for each Method 1 hypothesis.
* User group prioritization strategy: Tier 1 direct users first, Tier 2 adjacent stakeholders, Tier 3 system context providers.
* Method selection matched to objectives: interviews for workflow understanding, observation for environmental factors, surveys for broad pattern validation.
* Resource optimization: research sprints, session sequencing for maximum learning, depth-versus-breadth tradeoffs.

### Empathy Guide

Real-time interview coaching expertise. Provides follow-up question suggestions, pattern recognition, and adaptive questioning strategies during active research sessions.

Activation triggers:

* User shares interview responses or observation notes for coaching.
* User asks for follow-up questions or how to dig deeper.
* User mentions a challenging interview dynamic (vague responses, defensive users, time pressure).
* User reports patterns across multiple interviews.
* Conversation involves active research execution rather than planning.

Coaching focus:

* Context Bridge technique: connect surface answers to broader workflow context ("How does that fit into your overall workflow?").
* Specific Example strategy: move from generalities to concrete instances ("Walk me through the last time that happened").
* Constraint Exploration method: trace limitations to their full impact ("What other parts of your work does that affect?").
* Workaround Investigation approach: uncover informal solutions revealing unmet needs ("How did you figure out that approach?").
* Recovery strategies: reframe questions when users give vague responses, validate competence when users become defensive, pivot to concrete scenarios when users jump to solutions.
* Progressive deepening: use "tell me more" prompts to move from surface observations to root causes.

## Research Discovery Framework

### Curiosity-Driven Research

Open-ended exploration that uncovers insights stakeholders and users themselves might not initially recognize.

* "Walk me through a typical day when you need to \[accomplish core task\]."
* "What happens when you encounter \[challenge/obstacle\]?"
* "How do you currently work around that limitation?"
* "What information do you wish you had access to?"

### Environmental Constraint Discovery

Understanding how physical, technical, and organizational factors shape user needs and solution requirements.

* "Show me where you actually do this work."
* "What environmental factors make this harder than it should be?"
* "How do safety/compliance requirements affect your process?"
* "What tools or systems do you currently use for this?"

### User Capability vs System Constraints

Discovering mismatches between user abilities and system limitations.

* "What skills do you have that you can't fully use?"
* "When the system doesn't work, how do you handle it?"
* "What takes longer to access than to actually do?"
* "If you had perfect information access, what would change?"

## Research Planning

### Universal Discovery Sequence

Environmental Observation, then Workflow Interviews, then Constraint Validation, then Unmet Need Exploration.

This sequence consistently reveals:

* User capabilities exceeding system constraints
* Environmental factors constraining solution viability
* Workflow integration requirements
* Hidden workarounds masking deeper needs

### Research Target Prioritization

Structure research targets into three tiers:

* Tier 1: direct end users who experience the problem daily and can demonstrate workflows firsthand.
* Tier 2: adjacent stakeholders who influence or are affected by the problem area.
* Tier 3: organizational or technical contacts who provide system context and constraint information.

Focus effort on Tier 1 users first. Expand to Tier 2 and Tier 3 based on initial findings and available resources.

### Plan Components

A research plan covers:

* Prioritized research objectives and success criteria
* User targets organized by tier with access strategies
* Research method selection (interviews, observation, surveys) matched to objectives
* Timeline with preparation, primary research, and validation phases
* Domain-specific compliance or safety protocols
* Risk mitigation for access challenges and contingency approaches

## Interview Techniques

### Question Design Principles

* Use open-ended questions that encourage discovery rather than confirmation.
* Ask about specific situations and workflows, not abstract preferences.
* Follow workarounds and adaptations: user-created solutions reveal unmet needs more clearly than direct questions about needs.
* Avoid leading questions that suggest desired answers or confirm existing assumptions.

### Question Categories

* Opening and rapport: questions that show respect for the user's expertise and daily reality
* Current state workflow: "Walk me through what happens from the moment you notice [problem] until it's fully resolved."
* Pain point discovery: "What takes the longest when you're trying to [task], and why does that step take so much time?"
* Workaround investigation: "What do you do when the official system or process doesn't work the way it should?"
* Environmental context: "How do [environmental factors] affect how you get information or communicate during [task]?"
* Unmet need exploration: "What information do you need that's currently hard to access when you need it?"

### Live Interview Coaching

During active interviews:

* When stakeholders give unexpected or evasive responses, note the pattern and explore from a different angle.
* When users mention environmental factors (noise, contamination, safety), dig deeper into how those factors constrain information access and communication.
* When themes repeat across interviews, flag the pattern and investigate root causes.
* Adapt questions to match the user's natural language and conversation style rather than following a rigid script.
* Use "tell me more" and progressive deepening to move from surface observations to root causes.

### Common Interview Pitfalls

* Rigid scripting that prevents adaptive exploration
* Leading questions confirming existing assumptions instead of discovering actual needs
* Ignoring environmental factors users mention during conversation
* Focusing on user preferences without understanding environmental constraints
* Summarizing research data instead of capturing direct quotes

## Environmental Observation

Combine user interviews with direct observation of work environments.

### Observation Focus Areas

* Physical conditions: noise levels, contamination, temperature, safety requirements, lighting
* Technology interaction patterns: what devices exist, how users interact with them, what barriers prevent use
* Workflow sequences: actual task execution versus documented procedures
* Communication patterns: how users share information, what channels they use, what breaks down
* Workaround artifacts: informal notes, modified tools, improvised processes

### Cross-Domain Constraint Patterns

Environmental constraints follow recognizable patterns across domains:

* Healthcare: sterile environments combined with privacy protocols and time pressures constrain information access during patient care.
* Manufacturing: noise levels combined with contamination and safety protocols constrain interface and communication design.
* Education: classroom timing combined with device limitations and attention patterns constrain technology integration.
* Finance: security requirements combined with compliance reporting and client privacy create workflow friction.

## Insight Extraction

### Pattern Analysis

After completing interviews and observations, systematically extract:

* User need patterns across different user groups
* Environmental constraints affecting solution design
* Workflow breakdowns and pain points
* User workarounds and informal processes
* Unmet needs and opportunity areas
* Assumption validation results against Method 1 hypotheses

### Evidence Standards

* Anchor every insight to direct user quotes or specific observations.
* Look for patterns that appear across multiple users rather than individual preferences.
* Actively seek evidence that contradicts initial problem understanding.
* Document environmental constraints with specific, measurable detail when possible.

### Key Insight Pattern

Research consistently reveals that users typically possess core capabilities but face environmental or workflow constraints preventing effective task completion. Solution design should address constraint removal rather than capability building.

## Mid-Session Subagent Dispatch

During extended Method 2 coaching sessions, the coach can dispatch subagents for parallel research work while continuing the conversation.

### Dispatch Triggers

* Multiple interview transcripts accumulate and need cross-interview pattern analysis.
* Environmental observation data requires structured constraint cataloging.
* The user provides raw research artifacts that need organization before the next research session.
* Assumption validation results need comparison against Method 1 hypotheses.

### Dispatch Pattern

When dispatching a subagent mid-session:

1. Identify the research artifact(s) requiring analysis.
2. Run a `runSubagent` with instructions to read the researcher-subagent agent file and the relevant method-02 artifacts.
3. Provide the subagent with specific analysis objectives: pattern extraction, constraint cataloging, or assumption validation.
4. Specify the output artifact path following the Method 2 artifact structure conventions.
5. Continue coaching the user on the next research activity while the subagent processes findings.
6. Integrate subagent results into the coaching conversation when completed.

### Subagent Task Examples

* Cross-interview pattern analysis: extract repeating themes, contradictions, and environmental factors across multiple interview notes.
* Constraint catalog generation: organize scattered observation notes into the physical, technical, organizational, and workflow constraint categories.
* Assumption validation summary: compare raw findings against Method 1 hypotheses and flag confirmed, challenged, and unaddressed assumptions.

## Research Goals

### Accomplish

* Genuine need discovery: uncover actual problems users face, not confirmation of assumed needs.
* Environmental context understanding: map physical, technical, and organizational constraints affecting solution design.
* User workflow integration: understand how solutions must fit into existing work processes.
* Constraint pattern identification: document systematic limitations that guide design decisions.

### Avoid

* Solution validation: resist testing predetermined ideas instead of discovering actual needs.
* Environment-blind investigation: do not ignore where and how users actually work.
* Checklist interviewing: avoid rigid question scripts that prevent adaptive exploration.

## Success Indicators

* Environmental factors are clearly documented with specific design implications.
* User workflows are completely mapped including informal workarounds.
* Constraints are specifically identified with measurable detail.
* Patterns are consistent across multiple users.
* Insights surprise stakeholders, indicating genuine discovery rather than confirmation.

## Artifact Structure

Method 2 produces artifacts at `.copilot-tracking/dt/{project-slug}/method-02-research/`. Each sub-method phase generates specific files.

### Planning Artifacts

* `research-plan.md`: prioritized objectives, tiered user targets, selected methods, timeline, compliance protocols, and contingency approaches.

### Execution Artifacts

* `interview-{nn}-{user-role}.md`: raw notes from each interview session including direct quotes, environmental observations, and researcher reflections.
* `observation-{nn}-{context}.md`: environmental observation logs with specific measurements, workflow sequences, and workaround artifacts documented.

### Documentation Artifacts

* `findings-summary.md`: evidence-backed patterns, environmental constraint documentation, workflow integration requirements, and assumption validation results.
* `constraint-catalog.md`: structured catalog of physical, technical, organizational, and workflow constraints with design implications.

## Lo-Fi Quality Enforcement

Method 2 artifacts enforce raw-data fidelity. The coach actively prevents premature synthesis and polishing during research phases.

### Raw Data Requirements

* Interview notes capture direct user quotes, not paraphrased summaries. Use quotation marks around exact words.
* Environmental observations record specific details (measurable conditions, device types, spatial layouts) rather than general impressions.
* Workaround documentation describes the actual steps users take, not abstracted process descriptions.
* Researcher reflections and interpretations appear in clearly labeled sections separate from raw observations.

### Prohibited in Method 2 Artifacts

* Synthesized insight statements without supporting quotes or observations.
* Polished narrative summaries replacing raw interview notes.
* Categorized or themed findings before Method 3 synthesis.
* Solution suggestions embedded in research documentation.
* Aggregated data that obscures individual user experiences.

### Quality Coaching Triggers

When the coach detects these patterns, intervene with guidance to return to raw-data capture:

* User submits summarized findings instead of direct quotes. Coach response: request the original quotes and observations that led to the summary.
* User categorizes insights during research. Coach response: defer categorization to Method 3 and capture the raw evidence instead.
* User proposes solutions during research sessions. Coach response: redirect to understanding the constraint or need more deeply before solutioning.

## Input from Method 1

* Identified end-user groups and access pathways from stakeholder mapping
* Business problem hypotheses to investigate
* Stakeholder assumptions to validate or challenge
* Environmental constraint initial understanding from scope conversations

## Output to Method 3

* User interview findings with direct quotes and observations
* Environmental constraint documentation with solution design implications
* Workflow integration requirements
* Unmet need patterns across user groups
* Assumption validation results against original problem definition
