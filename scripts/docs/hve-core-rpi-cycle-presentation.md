---
title: HVE-Core RPI Cycle Presentation
description: Reference material for the RPI cycle execution flow, presentation outline, and Copilot chat mode usage
author: HVE Core Team
ms.date: 2026-02-19
ms.topic: reference
keywords:
  - hve-core
  - rpi
  - presentation
  - copilot
estimated_reading_time: 8
---

<!-- markdownlint-disable MD013 -->

Executing the RPI Cycle with HVE-CORE and GitHub Copilot: Guide and Presentation Outline
Hypervelocity Engineering Core (HVE-CORE) is Microsoft‚Äôs internal AI-powered toolkit that accelerates software development by providing refined prompts, clear instructions, and specialized Copilot chat modes1. It has been industry-proven at companies like AVEVA, Michelin, BMW, Hexagon, Kubota, and Nvidia to improve coding accuracy, automate repetitive tasks, and personalize solutions2. HVE-CORE directly addresses common enterprise development challenges ‚Äì such as slow progress on large codebases, lost tribal knowledge, inconsistent standards, and context-switching overhead ‚Äì by introducing a structured AI-assisted workflow. Central to this is the RPI framework (Research ‚Üí Plan ‚Üí Implement), which serves as ‚Äúguardrails‚Äù for developers and AI to work together effectively3. Instead of ad-hoc ‚Äúvibe coding‚Äù with an AI, RPI enforces disciplined phases that reduce hallucinations and boost productivity (cutting task completion time by up to 88% in internal trials4). The result: teams can ship faster and with higher quality by focusing on what to build, how to build it, and then building it ‚Äì in that order.
These statistics underscore why HVE-CORE and the RPI approach are needed. Below, we provide a detailed step-by-step guide to executing the RPI cycle in Visual Studio Code using HVE-CORE‚Äôs GitHub Copilot integration, followed by a presentation outline (for a 30-minute GUILD Day talk) that you can use to educate others on HVE-CORE and RPI. The guide includes best practices for each RPI phase, example Copilot prompt texts for each custom chat mode, and tips on involving various roles (engineers, PMs, TPMs, OSS contributors) in this hypervelocity engineering approach. We also integrate forward-thinking ideas (like Design Thinking) and a plan for a live demo. Let‚Äôs dive in.
RPI Cycle Phases and Best Practices with HVE-CORE
HVE-CORE‚Äôs RPI framework breaks work into three clear phases ‚Äì Research, Plan, Implement ‚Äì to systematically leverage AI assistance. Each phase has a distinct goal and uses dedicated Copilot chat modes (intelligent agents) to maximize effectiveness. Here‚Äôs an overview of the RPI cycle:
Why RPI? By strictly separating these phases, RPI enforces structured thinking and prevents the AI from ‚Äúrunning ahead‚Äù without direction. This dramatically reduces AI mistakes and avoids the costly revise-and-rework cycle. In Microsoft‚Äôs internal trials, engineers using RPI with Copilot completed tasks nearly 88% faster than those using unstructured prompting5. The RPI workflow acts as a safeguard against AI hallucinations by ensuring decisions are based on evidence from the start6. It‚Äôs also tool-agnostic ‚Äì while it‚Äôs designed with GitHub Copilot in mind, the principles apply to any AI coding assistant7. In fact, HVE-CORE‚Äôs custom Copilot chat modes were built to support each RPI phase, keeping the developer and AI in sync.
RPI Phase Details & Best Practices:
‚Ä¢ Research Phase: Begin by clearly defining the problem or task. Resist the urge to jump into coding. Instead, gather information: read relevant code, documentation, design docs, requirements, or user stories. Aim to fully understand the current state and constraints. Ask ‚Äúwhat are we solving and what do we have?‚Äù For example, if adding a feature or fixing a bug, inspect the codebase for similar implementations or references. Tip: Use version control history, existing Wiki/Markdown docs, and even chat with colleagues or search previous Team chats for context (HVE-CORE‚Äôs Task Researcher can search enterprise data when configured). By the end of Research, you should have a factual foundation ‚Äì e.g. a list of findings, excerpts, and clarified requirements ‚Äì without writing any new code yet8. This prevents false assumptions. (If the task is unfamiliar or vaguely defined, you might even precede Research with a Discovery step: ask high-level questions in ‚ÄúAsk Mode‚Äù to refine the problem ‚Äì more on this in the Design Thinking section below9.)
‚Ä¢ Plan Phase: Using the research insights, form a step-by-step plan. This could be a checklist of code changes, a series of subtasks, or even pseudo-code for each component. The plan should answer ‚Äúhow will we implement the solution?‚Äù in detail, but still without coding ‚Äì the focus is on design and sequencing. Keep the plan scoped: HVE suggests a ‚Äúthree-file plan‚Äù as a rule of thumb, meaning try to limit the implementation to touching ~3 files or logical units, which keeps tasks manageable. If the plan is large, consider splitting into multiple RPI cycles (iterate feature development in slices). Ensure each step in your plan is clear (e.g., ‚ÄúUpdate AuthService to validate JWT expiration‚Äù or ‚ÄúAdd unit tests for X scenario‚Äù). This plan will serve as the to-do list for the AI and you in the next phase10. A good plan also references the research (e.g., ‚ÄúFollow pattern used in module Y as found in research‚Äù). Essentially, Planning bridges the what and the do ‚Äì it‚Äôs where you exercise engineering judgment and make decisions based on the research, before any code changes.
‚Ä¢ Implement Phase: Now carry out the plan. Start a fresh Copilot chat session at this stage for the best results11 ‚Äì this clears out the lengthy research dialogue and focuses the AI on the specific implementation steps. Implement in iterative, testable chunks. After each step (or a small group of steps), run your code or tests to verify. The aim is to deliver working software that addresses the original task. During implementation, it‚Äôs crucial to maintain focus on the plan to avoid scope creep; if new findings or ideas emerge, note them but consider deferring or going back to research after completing the current cycle. HVE-CORE‚Äôs approach encourages using sub-agents and tools for context control ‚Äì for example, if you have a large codebase, open only the files you‚Äôre working on or use Copilot‚Äôs ‚Äúfocused‚Äù tools, so the AI doesn‚Äôt get distracted12. By the end of Implement, you should have results ready for review (code committed, feature working, etc.).
‚Ä¢ After implementation, a natural extension is a Review (or ‚ÄúReflect‚Äù) step: e.g., create a Pull Request and use an AI to review your changes. In HVE‚Äôs RPI framework, code review is often considered part of Implement or an immediate post-step. We will cover using the PR Review Copilot agent for this in our guide as well.
Remember: The RPI cycle is iterative and can be scaled. For a large project, you might do RPI for each major feature. For a quick bug fix, RPI might be fast (short research & plan). The key is discipline ‚Äì treat each phase separately even if it feels slow at first. This upfront investment pays off by eliminating trial-and-error later. As one HVE team motto puts it: ‚ÄúStructured phases kill the AI rework loop.‚Äù13 14
Using HVE-CORE‚Äôs GitHub Copilot Chat Modes at Each Stage
The HVE-CORE VS Code extension (üì¶ available via the Visual Studio Marketplace as ‚Äúise-hve-essentials.hve-core‚Äù) provides custom Copilot chat modes tailored to each RPI phase and other developer tasks. These specialized modes are essentially ‚ÄúAI agents‚Äù with role-specific instructions. By invoking them, you get more focused and effective AI assistance than the generic Copilot. There are five main chat modes in HVE-CORE (plus an optional ‚ÄúAsk Mode‚Äù which is basically the vanilla Q&A style):
Each mode is invoked by typing the @command in the GitHub Copilot chat (in VS Code), followed by your request. For instance, typing @task-researcher will activate the research agent, and you can then ask your question. Under the hood, these are implemented as specialized system prompts that guide the LLM to act in the desired role, but as a user you simply address them by name. Using the correct mode for each phase dramatically improves Copilot‚Äôs usefulness ‚Äì developers report that the Task Planner‚Äôs plans and PR Review‚Äôs detailed critiques feel like having an expert pair-programmer focusing exactly on that aspect of work15.
Step-by-Step RPI Execution (with Example Prompts):
To illustrate how you‚Äôd execute an RPI cycle using HVE-CORE in VS Code, let‚Äôs walk through the process step by step. In this scenario, suppose we want to create a 30-minute presentation deck about HVE-CORE and the RPI cycle (which is exactly your goal for the Guild Day talk). We‚Äôll use RPI to accomplish this task in an AI-assisted way ‚Äì essentially ‚ÄúAI-assisted engineering‚Äù not for code, but for content creation (the same principles apply!). Along the way, we‚Äôll demonstrate the prompts you‚Äôd give to each Copilot agent.
Step 1: Environment Setup for HVE-CORE ‚Äì First, ensure you have the HVE-CORE toolkit ready in VS Code. This means: clone the microsoft/hve-core repository locally (placing it alongside your project or in a common tools folder), and then add a small config so VS Code knows about it. Specifically, add the recommended 3-line settings snippet to your workspace or user settings (.vscode/settings.json) to activate HVE-CORE in all your projects16 17. This snippet typically sets up the HVE-CORE prompts/agents path. After this, install the HVE-CORE VS Code extension (if not already) from the Marketplace. Result: You now have access to all HVE custom chat modes and commands inside Copilot chat.
‚Ä¢ Verification: You should see the custom slash commands (like /git-setup) and chat personalities (like Task Researcher, etc.) available. For example, try typing ‚Äú/git-‚Äù or ‚Äú@task‚Äù in Copilot chat to see if they auto-complete.
Step 2: Define the Task (Problem to Solve) ‚Äì Clearly state what you need to do. In our case: ‚ÄúCreate a 30-minute PowerPoint presentation (two 15-min parts) introducing HVE-CORE and the RPI framework to a mixed technical/non-technical audience.‚Äù This is essentially our requirements. Write down any specific sub-requirements (from your prompt): e.g., include speaker notes, use diagrams (ASCII, Mermaid, etc.), align with previous HVE decks visually, highlight roles (PM, TPM, dev, etc.), mention Design Thinking integration, and provide contribution resources. This list itself can be part of the prompt to the Task Researcher, so it knows what information to look for.
Step 3: Research Phase (Task Researcher) ‚Äì Open a new Copilot Chat and activate the Task Researcher mode. Provide it with the task context and ask it to gather relevant information. Since we have many details, you might break the research into a couple of queries focusing on different angles. For example:
‚Ä¢ Prompt to Task Researcher:
The Task Researcher will now comb through the HVE-CORE repository, documentation, and even enterprise knowledge (since it‚Äôs configured to have that access) to return a research summary with citations. For example, it might return points about HVE-CORE‚Äôs definition (‚ÄúAI toolkit enabling hypervelocity engineering, used by AVEVA, BMW, etc.‚Äù)18, the RPI timing and 88% efficiency stat19, pain point statistics (40% context-switch cost, etc.)20, and descriptions of each agent mode21 22 ‚Äì all with source links to the slides and docs. It might even find an ASCII diagram in a markdown file if one exists (e.g., a Mermaid diagram depicting RPI flow). At this stage, ask follow-up questions to Task Researcher as needed to clarify anything. For instance, ‚ÄúWhat does D-RPI mean?‚Äù (it would explain the Discovery phase variant23). Or ‚ÄúFind any mention of Design Thinking in relation to HVE.‚Äù This interactive research could produce a comprehensive set of notes.
‚Ä¢ Tip: If you have previous Python scripts or content (like earlier slide decks or automation code) that are relevant, you can feed them into Task Researcher for analysis. In our case, you mentioned having scripts that use python-pptx and Pillow to generate decks. You could prompt: @task-researcher Analyze the script "make_hve_deck.py" (provided below) which I used to create past HVE decks. Summarize how it structures slides and handles images (Pillow for diagrams), and note anything I should reuse or improve. This way, the Researcher can extract knowledge from your prior work ‚Äì e.g. how you formatted slides or embedded Mermaid diagrams as images ‚Äì ensuring the new plan aligns with proven methods.
By the end of the Research phase, you should have a research document (either in the chat or exported to a file) containing all the key information, quotes, and references to source materials. In our example, that includes definitions of HVE-CORE, details of RPI, the five Copilot modes, important stats (40%, 88%, etc.), relevant diagrams or figures from HVE community decks, and notes on including Design Thinking and multiple roles. This is your factual foundation.
Step 4: Plan Phase (Task Planner) ‚Äì With the curated research at hand, switch to the Task Planner mode. Now you‚Äôll ask Copilot to help outline the content and steps to actually produce the deliverable (the PowerPoint deck, in this case). The plan should cover both what slides to create and how to execute their creation. Essentially, we need two layers of planning: (a) the presentation structure (slide titles and content points), and (b) the process of generating those slides (possibly via a script or manual writing). We can tackle these one after the other:
‚Ä¢ Plan the Presentation Content: Prompt Task Planner to outline the slide deck. For example:
‚Ä¢ The Task Planner will generate a structured list of slide headings and sub-points, essentially forming the storyboard of your deck. For instance, it might produce:
a. ‚ÄúSlide 1: Title ‚Äì HVE-CORE & Hypervelocity Engineering (speaker introduction)‚Äù
b. ‚ÄúSlide 2: What is HVE-CORE? ‚Äì Definition, used by X, Y companies, toolkit components‚Äù,
c. ‚ÄúSlide 3: Challenges in Enterprise Dev ‚Äì bullet: large codebases, lost knowledge (15-20h lost/week24, etc.), context switching (40% loss25)‚Äù,
d. ‚ÄúSlide 4: RPI Framework Overview ‚Äì define Research, Plan, Implement, show 88% faster stat26‚Äù,
e. ‚ÄúSlide 5: Custom Copilot Modes ‚Äì list Task Researcher, Planner, etc., each with one-line description27 28‚Äù, ‚Ä¶ and so on up to perhaps slide 10 or 12 covering resources. It will likely integrate the requirements we gave (roles, Design Thinking, etc.) as separate slides or bullets. We should see a clear two-part structure if we mentioned splitting into Part 1 and Part 2 ‚Äì e.g., slides 1‚Äì6 labeled Part 1 and 7‚Äì12 as Part 2 (the Planner might indicate ‚Äú(Break for Part 2)‚Äù in the list or similar).
‚Ä¢ Review this outline. It should cover all points; if something is missing or not to your liking, ask Task Planner to adjust. For example, ‚ÄúPlease include a slide highlighting how a PM or TPM would use HVE-CORE (maybe as part of the roles slide).‚Äù You can iterate until the outline fits your vision.
‚Ä¢ Plan the Implementation (if automating slide creation): Now, if you intend to automatically generate the PowerPoint slides (using code, as you did with python-pptx), our plan needs a section on that. You might ask Task Planner for a high-level plan of the implementation process. For example:
‚Ä¢ The planner might produce a sequence like: ‚Äú1. Use python-pptx to create a new PPTX and add slides for each outline item. 2. For each slide, add a title and content placeholders. 3. If an ASCII or Mermaid diagram is available (from research), render it to an image (possibly using a tool or manual step) and insert into the slide via Pillow. 4. Add speaker notes to each slide (using the notes_slide feature of python-pptx) with the narration points. 5. Save the deck and review.‚Äù This ensures we haven‚Äôt forgotten the technical steps required to go from plan to actual slides. At this point, our Plan phase yields two things: a presentation outline and an implementation plan for creating the slides, both derived from our research.
Step 5: Prompt Refinement (Optional ‚Äì Prompt Builder) ‚Äì Before jumping into coding or content creation, it can be beneficial to refine any complex prompts or instructions. This is where Prompt Builder is handy. In our case, you might use it to ensure the AI maintains a certain style or format throughout. For example, we can create a style guide for the slides:
‚Ä¢ Prompt to Prompt Builder:
‚Ä¢ The Prompt Builder might output a well-structured list of instructions like: ‚Äú1. Use Microsoft official visuals or simple diagrams from the repository for consistency. 2. Use the exact phrasing for terms as in HVE resources (e.g., refer to ‚ÄòRPI framework‚Äô and not just ‚Äòprocess‚Äô). 3. Include the Microsoft copyright disclaimer on the title slide as seen in previous decks29,‚Äù etc. You can take these guidelines and keep them in mind (or even programmatically apply them when generating slides). Essentially, Prompt Builder is helping to codify the style and quality criteria before implementation.
Another use of Prompt Builder could be to help craft the content of the speaker notes or demo script in a polished way. For instance, if you want a compelling narrative, you could ask:
1     @prompt-builder Develop a concise narrative for introducing the RPI framework to a non-technical audience, using an analogy if possible (for speaker notes).
This might give you a nice analogy (like comparing RPI to planning a road trip: you plan the route before driving, etc.) that you can incorporate into your speaker notes.
This step is optional, but it showcases how you might interject at any point to improve or enforce the quality of the outputs.
Step 6: Implementation Phase (Task Implementor) ‚Äì Now it‚Äôs time to actually create the slides and content. If you are proceeding with manual creation (writing the slides yourself in PowerPoint or a doc), you might use the Task Implementor agent to help draft the text for each slide and the speaker notes. If you are coding the deck with Python, you‚Äôll use Task Implementor to assist in writing that code. We‚Äôll consider both approaches:
A. Using AI to draft slide content (no code): You can go slide by slide, using the outline from the plan. For each slide, provide the Task Implementor with the slide title and the key points, and ask it to flesh out the slide text or speaker notes. For example:
‚Ä¢ Prompt to Task Implementor:
‚Ä¢ Task Implementor will then generate a concise paragraph for the speaker notes, perhaps: ‚ÄúHVE-CORE is our unified AI toolkit that helps developers move at hypervelocity. It provides ready-made smart prompts and instructions, and even custom ‚ÄòAI assistants‚Äô within GitHub Copilot, all designed to help us write better code faster. Industry leaders like AVEVA and BMW have successfully used HVE-CORE to speed up their projects, proving its value in real-world scenarios.‚Äù You can iterate or tweak the output as needed. Repeat this for each slide‚Äôs content. Task Implementor is useful here because it ‚Äústays on task,‚Äù using the context of the outline and research without introducing off-topic info. It ensures the slides remain aligned with the plan and factual (since the research with citations is in the context).
‚Ä¢ For slides that require diagrams, Task Implementor can help generate ASCII art or pseudo-Mermaid if needed. For example, if one slide needs an architecture sketch, you can describe what you want, and the AI might produce a simple ASCII diagram or Mermaid code that you could later render. (Since HVE encourages use of such tools, the model might be aware of some syntax to do it.)
B. Using AI to write the Python code for slide generation: If you prefer to programmatically create the deck (to easily incorporate diagrams or apply consistent formatting), open a Python file in VS Code (e.g., generate_deck.py) and use the Task Implementor to help write it. Start by prompting it to set up the structure:
‚Ä¢ Prompt to Task Implementor:
‚Ä¢ The AI will start writing Python code accordingly. It might write the import statements (python-pptx library usage) and begin constructing the presentation. Because the prompt is detailed, it will likely follow the steps: e.g., create the presentation object, add a title slide with the given text30, then loop through slide data. It may need help for specifics like adding speaker notes (which in python-pptx means using the notes_slide attribute of a slide). You can either let it draft everything or do it incrementally (preferred, as you can check each part). For instance, after it creates the title slide code, you can run that to test it, then proceed.
o Incorporating Diagrams: If the plan called for using a Mermaid diagram from a repo markdown, you have a few options. Mermaid can be generated to an SVG/PNG using command-line tools or utilities, but since we might not have internet or those tools available in this environment, an alternative is to manually recreate a simplified diagram. The AI can assist by generating ASCII art that you then convert to an image using Pillow (by drawing shapes/text). For example, if illustrating the RPI cycle, you might have the AI produce something like a simple flowchart with text:
o You can then create an image from this using Pillow in Python. Task Implementor could help writing the Pillow drawing code if needed.
o Ensuring Style Consistency: Remind the AI about the styling guidelines from Prompt Builder. For instance, ensure it places the Microsoft disclaimer on the title slide (as in the HVE decks)31, uses similar phrasing for slide headings as found in HVE materials (the AI might do this automatically since the research context likely includes lines from the actual HVE-Core decks; e.g., it might use ‚ÄúPain Points in Enterprise Development‚Äù like in the reference slides32). You can also ask it to use a particular template or theme if one is available.
o Speaker Notes via Code: You can copy the speaker notes content that was drafted in approach A, and have the script insert them. For each slide in the code, use something like:
o The Task Implementor can help write this once and it can be reused for each slide. Make sure to break lines appropriately (the AI can figure it out, possibly citing how to do it).
‚Ä¢ Continue this coding process until the script is complete. Then run the script to generate the actual PowerPoint file. Open it and verify the slides look correct.
In practice, you might choose either to manually write the content with AI help (approach A) or write code to generate it (approach B). The end result should be the same ‚Äì a finished slide deck with all requirements met.
Step 7: Review Phase (PR Review) ‚Äì If you wrote a script to generate the deck (or even if you just have a bunch of content), it‚Äôs wise to do a final review. Use the PR Review agent to double-check everything:
‚Ä¢ If you used code: open the pull request or diff of your generate_deck.py script and ask:
‚Ä¢ The agent will scan your code (using full context of the repository if needed) and point out issues. For example, it might catch if you forgot to save the presentation or if an image file path is incorrect, etc. It may also suggest enhancements, like refactoring repetitive code into a function, or ensuring that text does not overflow slides.
‚Ä¢ If you have the final PowerPoint content ready (say as a set of bullet points and notes), you could alternatively use PR Review mode in a ‚Äúcontent review‚Äù capacity by pasting the slide content text. For instance:
‚Ä¢ The agent will treat it like a document diff and highlight any factual inconsistencies (comparing against its knowledge of the research context) or suggest if something important is missing. It might say, for example, ‚ÄúSlide 3 mentions challenges but doesn‚Äôt include the statistic about weekly hours lost33 ‚Äì consider adding that for impact.‚Äù This is incredibly useful for catching omissions and ensuring your deck is solid.
At this point, you have completed the RPI cycle: you researched thoroughly, planned meticulously, implemented the solution (the presentation deck), and even had an AI review it. If time permits, you could do a test run of the presentation and adjust as needed ‚Äì another mini RPI loop (Research any unclear parts, Plan updates, Implement changes, Review again). HVE-CORE‚Äôs philosophy encourages iterative refinement.
Integrating Design Thinking and D-RPI (Discovery Phase)
HVE-CORE is forward-looking, and one area of exploration is combining RPI with Design Thinking principles. In practice, this often means adding a Discovery or Define phase before ‚ÄúResearch‚Äù when tackling complex or ambiguous projects ‚Äì HVE-CORE calls this D-RPI (Discovery + RPI). The idea is to use Copilot‚Äôs Ask Mode (or a general-purpose chat) to simulate the ‚ÄúEmpathize‚Äù and ‚ÄúDefine‚Äù stages of design thinking. For example, if the requirements are unclear, you might have a brainstorming Q&A session with the AI (Ask Mode) or a stakeholder interview. This corresponds to the Discovery Phase in D-RPI: an open-ended exploration to clarify the problem and user needs34 35.
In our Guild Day presentation scenario, Discovery might involve asking, ‚ÄúWho is the audience and what do they care about?‚Äù and ‚ÄúWhat do they already know about HVE-CORE?‚Äù ‚Äì essentially understanding the user (audience) to tailor the content. While we assumed that in planning, explicitly doing it with the AI could yield insights (for instance, the AI might suggest simplifying technical jargon for PMs, or focusing on business outcomes to engage managers).
Once Discovery (empathize/define) is done, you proceed with Research (which parallels Ideation in design thinking by exploring existing knowledge and possible solutions), then Planning (which is like Prototyping a solution on paper), and Implementation (like building the actual Prototype/Implementation), followed by testing or review (analogous to a Test phase). In essence, RPI aligns well with design thinking:
‚Ä¢ Discovery (Empathize/Define): understand the problem space and audience needs (optional, for new or unclear projects)36.
‚Ä¢ Research (Ideate on approach with evidence): gather information and ideas constrained by reality (what‚Äôs possible, what existing assets can be leveraged).
‚Ä¢ Plan (Prototype in plan form): create a low-fidelity representation of the solution (an action plan or design outline).
‚Ä¢ Implement (Test/Build): build the actual solution and test it (writing code or content; then run it and see results).
‚Ä¢ Review (Gather Feedback): review the output (via tests or PR Review agent) which is akin to getting feedback and validating with requirements.
By highlighting D-RPI and the similarity to design thinking in our presentation, we show a ‚Äúforward-thinking‚Äù approach: HVE-CORE isn‚Äôt just about coding faster; it‚Äôs about injecting AI into the entire creative problem-solving process in engineering. This can open a discussion on how future workflows might include more AI-driven discovery, user research, or even automated UX prototyping as part of hypervelocity engineering.
(We will include a slide on this in the presentation outline to educate the audience on these concepts.)
How HVE-CORE Supports Different Roles in the Organization
One important point for a general audience is that HVE-CORE is not only for software developers. It provides tools that can be used by various roles involved in a project‚Äôs lifecycle, promoting cross-disciplinary efficiency:
‚Ä¢ Software Engineers (Developers): This is the primary user base. Engineers benefit from Task Researcher to quickly learn unfamiliar code or APIs, Task Planner to break down user stories or bugs into implementation steps, Task Implementor to accelerate coding while adhering to standards, and PR Review to catch issues before merge37 38. HVE-CORE also automates git workflows (e.g. /git-commit for conventional commit messages39), saving developers time on routine tasks. The net effect is more time spent on solving problems and less on slogging through setup, context gathering, or repetitive edits.
‚Ä¢ Technical Program Managers (TPMs) and Engineering Leads: TPMs can leverage HVE-CORE in the planning and coordination aspects. For example, they might use Task Researcher to aggregate information for a project kickoff (pulling data from requirement documents or past project retrospectives), then Task Planner to outline a project roadmap or a detailed implementation plan which developers can execute40 41. There‚Äôs even an AI-powered GitHub backlog manager in HVE-CORE (introduced around version 2.3) that TPMs can use to generate and manage work items from high-level objectives42. TPMs also benefit from the consistent documentation HVE encourages ‚Äì using Prompt Builder to draft Architecture Decision Records or design docs means less guesswork and higher quality specs across the team43 44.
‚Ä¢ Project Managers (PMs) / Business Analysts: Non-coding roles can still use HVE-CORE to accelerate their work. For instance, a PM could use Task Researcher to quickly gather customer pain points or usage data from disparate sources (like searching Teams for user feedback on a feature). They might use Prompt Builder to formulate clear problem statements or user stories (ensuring the AI captures business requirements accurately). When preparing status reports or slide decks for stakeholders, they could employ Copilot in research or planner mode to gather facts and structure the narrative. In our case, the presentation we‚Äôre creating could itself be the work of a PM using these tools to explain an engineering concept. By enforcing a structured approach, HVE-CORE helps non-engineers collaborate with technical teams ‚Äì for example, a PM can generate a draft PRD (Product Requirement Document) using HVE prompts and then have engineers review it, rather than starting from scratch. The agentic documentation tools in HVE (for PRDs and ADRs) are built exactly for this cross-role collaboration45.
‚Ä¢ OSS Contributors / New Team Members: HVE-CORE is extremely useful for onboarding. If you‚Äôre a new contributor to an open-source project (like Edge AI or the Robotics Accelerator which are based on HVE-CORE46 47), you can use RPI to get up to speed and make meaningful contributions quickly. For example, you might pick a ‚Äúgood first issue‚Äù and run Task Researcher to understand the codebase area, then use Task Planner to outline your solution approach ‚Äì essentially learning by doing in a guided manner. Bill Berry, the lead of HVE, encouraged new team members to ‚Äúpick an issue and RPI it‚Äù ‚Äì meaning even if it‚Äôs your first HVE contribution, the RPI agents will keep you on track and enforce good practices48 49. This lowers the barrier to entry for open-source or cross-team contributions, because the AI provides just-in-time guidance on the project‚Äôs conventions and context. It‚Äôs like having an expert mentor available 24/7. Community contributors can also utilize the built-in prompts for things like creating consistent commit messages and PRs, ensuring their contributions meet the project‚Äôs standards effortlessly50 51.
‚Ä¢ Solution Architects / UX Designers: While HVE-CORE is developer-centric, it fosters a culture of thorough documentation and iterative design that architects and designers appreciate. The research and planning outputs (research docs, plans, ADRs) can be shared with architects for review. Also, architects can use the same RPI approach to, say, evaluate a new technology integration: Research might involve assessing technical feasibility, Plan could outline architectural changes, and Implement might be a proof-of-concept; Prompt Builder can encode architectural principles as rules the AI should follow (for example, ‚Äúalways consider security and scalability constraints‚Äù). For UX designers or design thinkers, HVE-CORE can assist in generating user journeys or prototypes from descriptions (with tools like PowerApps or using Copilot for UX, outside the scope of core HVE, but conceptually similar in approach).
In summary, HVE-CORE provides a common AI-assisted workflow that different roles can tap into. It helps break silos by making technical information more accessible (via Researcher summaries), encouraging shared planning (everyone can read and contribute to the AI-generated plan), and maintaining project artifacts in a consistent format. The universal prompts and instructions (for coding standards, documentation templates, etc.) ensure that whether a PM is creating a backlog item or an engineer is writing code, both are following best practices set by the organization52. This significantly reduces the friction in handoffs between roles.
For the Guild Day presentation, emphasizing multi-role support will show that HVE-CORE is not just an engineering toy, but a comprehensive productivity suite. It empowers entire teams: from planning to development to project management. (We will include a dedicated slide on how different roles use HVE-CORE, listing examples like above.)
30-Minute GUILD Day Presentation Outline (with Speaker Notes)
Below is a proposed slide-by-slide outline for a 30-minute presentation on HVE-CORE and the RPI cycle, designed to be delivered in two 15-minute parts (e.g., Part 1 and Part 2). This outline incorporates all requested elements: clear explanation of RPI and HVE-CORE, diagrams/visuals aligned with existing Microsoft HVE decks, forward-looking ideas (Design Thinking integration), role-specific perspectives, and pointers for how to get started and contribute. Each slide includes concise speaker notes to guide the presenter on what to say.
Session 1 (First 15 minutes): Introduction & Core Concepts
‚Ä¢ Slide 1: ‚ÄúMicrosoft HVE-CORE: Hypervelocity Engineering in Action‚Äù ‚Äì Title slide.
Speaker notes: Welcome everyone, introduce yourself (e.g., ‚ÄúHi, I‚Äôm Alain Uyidi, a Senior Software Engineer in Microsoft‚Äôs Industry Solutions Engineering‚Äù). Introduce the session topic: HVE-CORE, Microsoft‚Äôs Hypervelocity Engineering toolkit, and the RPI framework. Mention that this talk is split into two parts of 15 minutes each: first part covering what HVE-CORE and RPI are, second part demonstrating how it works in practice. (Include the Microsoft logo and a disclaimer on the slide, similar to official decks53.)
‚Ä¢ Slide 2: ‚ÄúWhat is HVE-CORE?‚Äù ‚Äì Definition and value proposition.
o HVE-CORE = Hypervelocity Engineering Core ‚Äì a unified AI toolkit for software teams.
o Provides refined prompts & instructions and custom AI ‚Äúagents‚Äù to accelerate development54.
o Proven in the field: Used by industry leaders like AVEVA, Michelin, BMW, and others to boost productivity55 56.
o Enables Hypervelocity: helps teams deliver faster without sacrificing quality.
Speaker notes: Explain that HVE-CORE was built by our team to codify best practices in AI-assisted software engineering. It‚Äôs essentially a collection of tools that sit on top of GitHub Copilot, Visual Studio Code, and Azure DevOps/GitHub, to help engineers and managers work smarter. Emphasize that it‚Äôs battle-tested ‚Äì not just theory, but used in real projects (name-drop a couple of the big companies where it‚Äôs been used as per the slide). The key takeaway: HVE-CORE brings together everything you need (prompts, settings, agent modes, workflows) to practice ‚Äúhypervelocity‚Äù ‚Äì which means rapidly delivering value in iterative, safe increments with AI‚Äôs help.
‚Ä¢ Slide 3: ‚ÄúWhy Hypervelocity? ‚Äì Challenges in Traditional Development‚Äù ‚Äì The pain points HVE-CORE addresses.
o Teams struggle with large & multiple codebases ‚Äì feature development slows as code grows; knowledge silos form when people leave57.
o Inconsistent standards across projects ‚Äì leads to outdated docs, flaky builds, and confusion for newcomers58.
o Developers lose 15‚Äì20 hours/week dealing with repetitive tasks and relearning context59.
o Unstructured ‚Äúvibe coding‚Äù with AI fails: giving AI loose or overly big tasks yields incorrect or bloated code60.
o Long PRs with minimal guidance to AI = missed issues or superficial suggestions61.
o 40% productivity loss from constant context-switching and lack of guidance for AI62.
(Include an illustration: perhaps a frustrated developer clipart with many puzzle pieces or a clock icon to represent lost time63.)
Speaker notes: Paint the picture of a typical enterprise dev scenario ‚Äì codebases are huge, people come and go (and with them, important knowledge), each repository has its own conventions, documentation can‚Äôt keep up, and manual processes waste a lot of time. Mention the stats: ‚ÄúWe found that up to 15‚Äì20 hours per developer per week were wasted on just figuring things out or doing boilerplate work64, and context switching due to scattered information costs about 40% of productivity65.‚Äù Also describe the early experiences with naive use of AI coding assistants (what we call ‚Äúvibe coding‚Äù): where someone just tells Copilot ‚Äúbuild me this feature‚Äù in one go ‚Äì it often results in nonsense or huge code changes that don‚Äôt work66. Without a structured approach, the AI might also only help superficially (like fixing small lint errors in a PR but missing bigger bugs67). This slide motivates why we need HVE-CORE and RPI as a solution to these problems. The audience (especially managers) should resonate with these pain points.
‚Ä¢ Slide 4: ‚ÄúHypervelocity Solution: RPI Framework (Research ‚Üí Plan ‚Üí Implement)‚Äù ‚Äì Introduce the RPI process.
o Research (30‚Äì45 min): Gather facts and context without coding. Build a strong foundation (addresses the knowledge gap issue)68.
o Plan (10‚Äì15 min): Develop a clear roadmap or checklist from the research. Small, well-defined tasks (prevents giving AI vague/broad prompts)69.
o Implement (60‚Äì90 min): Execute the plan in a fresh session, using focused AI assistance for each step (prevents confusion and large, risky changes)70.
o (Visual suggestion: Show the three phases in a flow diagram with arrows: Research ‚Üí Plan ‚Üí Implement, maybe with an icon for each (e.g., magnifying glass, checklist, keyboard). Possibly annotate with the time percentages.)
o Up to 88% faster completion vs. unstructured approach71 (e.g., what used to take a week might take one day).
Speaker notes: Define each phase of RPI clearly. ‚ÄúResearch, Plan, Implement ‚Äì it‚Äôs fairly self-explanatory: first learn and understand, then design a solution, then build it. What‚Äôs novel is applying this rigorously with AI in each step. By preventing the AI from doing everything in one shot, we avoid those hallucinations and mistakes. Instead, we harness the AI in a controlled manner at each phase.‚Äù Highlight how each phase addresses the earlier challenges: Research recovers lost context and ensures we don‚Äôt reinvent the wheel; Plan means we give AI specific, well-scoped instructions (no more ‚ÄòAI, do everything‚Äô errors); Implement in a fresh context avoids the model being confused by too much prior chat history and allows using specialized coding agents. Mention the internal stat: using RPI, some teams saw task cycle times drop dramatically ‚Äì up to 88% reduction in time72. That means what was a multi-day or multi-week effort can sometimes be done in hours, thanks to this structure. The audience should grasp that RPI is the cornerstone methodology enabling hypervelocity.
‚Ä¢ Slide 5: ‚ÄúCustom AI Agents in Copilot (HVE-CORE Toolkit)‚Äù ‚Äì The specialized Copilot chat modes.
o Task Researcher: AI that does evidence-based research (answers ‚ÄúWhat do we need/what do we have?‚Äù)73.
o Task Planner: AI that turns research into an actionable plan (‚ÄúHow do we do it?‚Äù)74.
o Task Implementor: Focused coding assistant that follows the plan step-by-step (helps you write the code)75.
o Prompt Builder: Helps create strong custom instructions or prompts (for new agents, complex tasks, or documentation)76.
o PR Review: AI code reviewer that inspects changes deeply with full context (‚ÄúDid we do it right?‚Äù)77.
(Visual: Perhaps depict these five as distinct icons or sections, e.g., a research icon for Researcher, a checklist for Planner, keyboard for Implementor, a magic wand for Prompt Builder, and a magnifying glass or checkmark for PR Review. Possibly arranged in a circle or flow.)
Speaker notes: Explain that our team extended GitHub Copilot with custom ‚Äúchat modes‚Äù to support RPI. Each mode is like a specialized assistant with expertise in a certain area:
ÔÇß Task Researcher scours your codebase and connected knowledge bases to give you answers with references (mention that it‚Äôs great for things like, ‚ÄúWhere in the code is X handled?‚Äù or ‚ÄúWhat does library Y do?‚Äù and it will answer with quotes from the code/docs)78.
ÔÇß Task Planner uses the research to propose a plan. It writes out a step-by-step to-do list ‚Äì you can actually ask it for a plan touching no more than 3 files, for example, to keep things manageable79.
ÔÇß Task Implementor is used once you have a plan ‚Äì it helps you write the actual code for each step, keeping context limited to that step so it doesn‚Äôt get ‚Äúdistracted.‚Äù It‚Äôs like pair-programming with the AI on a very specific task80.
ÔÇß Prompt Builder is a bit meta ‚Äì it helps you create better prompts. This is useful if you want to design your own AI guidance (for example, to enforce certain coding standards via custom instructions, or to prepare a prompt for a different generative model)81. It‚Äôs our way of teaching users prompt engineering.
ÔÇß PR Review is used at the end ‚Äì unlike GitHub‚Äôs built-in PR review, this agent actually understands the entire codebase and can do a thorough review. It‚Äôs caught things like security issues or logical bugs that a normal review might miss, because it can reason about the whole system82.
‚Ä¢ Emphasize that these agents together cover the full development lifecycle (the slide might even say ‚Äú5 Specialized Agents = 100% coverage of dev lifecycle‚Äù as per our internal tagline83 84). This is a major differentiator ‚Äì instead of one generic AI, we have a team of AIs with different roles, just like a real team.
‚Ä¢ Slide 6: ‚ÄúLive Demo: RPI in Action (Research & Plan)‚Äù ‚Äì Transition to demo part 1.
o (This slide can list the demo scenario and which parts of RPI will be shown now. For example: ‚ÄúDemo Scenario: Using RPI to add a new feature to an existing app (Part 1: Research & Plan)‚Äù)*
o We will demonstrate the Research and Plan phases using Task Researcher and Task Planner.
o Scenario: Suppose we need to add a ‚Äúdark mode‚Äù setting to an internal web app. We‚Äôll use HVE-CORE agents to research the code and plan the changes.
Speaker notes: Introduce the live demo to the audience. Explain that seeing is believing ‚Äì you‚Äôll show how to apply RPI with the Copilot agents. Describe the fictitious scenario for context (choose a simple feature or bug relevant to your work; here we used ‚Äúadd a dark mode toggle‚Äù). Clarify that in this first part, you‚Äôll focus on the Research and Plan steps due to time constraints, and in Part 2 you‚Äôll cover Implementation. This manages audience expectation and keeps the demo segment focused. Then switch out of slides to the demo environment (Visual Studio Code) to perform the Research and Plan live:
ÔÇß Demo (Research): Show how to invoke Task Researcher (e.g., type @task-researcher in the Copilot chat). Ask a question about the codebase: ‚ÄúWhere are theme settings managed?‚Äù or ‚ÄúWhat would need to change to add a dark mode?‚Äù Narrate how the agent is pulling up references from the code (maybe it shows a snippet of a config file or a UI component)85. Highlight the citations ‚Äì mention that this gives you confidence in the info.
ÔÇß Demo (Plan): Copy any important findings to a temporary document (if needed), then invoke @task-planner to create an implementation plan. For example, prompt: ‚ÄúCreate a plan to implement a dark mode feature given the above information.‚Äù Watch as it produces a step-by-step plan (e.g., ‚Äú1. Add a user preference in settings. 2. Update the UI theme component‚Ä¶ 3. Adjust tests‚Ä¶‚Äù). Scroll through the plan and point out how it‚Äôs structured and actionable.
ÔÇß Keep this demo segment within ~5-7 minutes. Conclude Part 1 by saying that in the second half, you‚Äôll continue with the Implementation and show more of HVE-CORE‚Äôs capabilities.
(End of Part 1 ‚Äì likely at around the 15-minute mark. Encourage the audience to hold questions for the end of Part 2, or take one quick question if ahead of time.)
Session 2 (Next 15 minutes): Advanced Topics, Implementation & Q&A
‚Ä¢ Slide 7: ‚ÄúLive Demo: RPI in Action (Implement & Review)‚Äù ‚Äì Demo part 2 intro.
o Continuing the demo ‚Äì now using Task Implementor and PR Review to execute and verify the plan.
o We‚Äôll implement the dark mode feature step-by-step with AI, then have AI review the changes.
Speaker notes: Briefly recap Part 1‚Äôs outcome: ‚ÄúWe researched the code and got a plan. Now, in Part 2, let‚Äôs complete the cycle by implementing and reviewing the changes.‚Äù Then jump into the live demo again:
ÔÇß Demo (Implement): In VS Code, perhaps open a file that needs editing (as per the plan, e.g., a ThemeManager.js). Invoke @task-implementor and give it a specific task from the plan: ‚ÄúImplement step 1: add a darkMode flag to user settings with a default of false.‚Äù The AI will generate code in the file diff. Accept it if correct, or tweak as necessary. Proceed to the next step: for example, ‚ÄúNow implement step 2: if darkMode is enabled, load dark CSS‚Äù, etc. This shows how the AI can be re-engaged for each subtask, keeping context limited to relevant files. If something goes wrong (AI introduces an error), mention how the plan and research help correct it (you can refer back ‚Äì ‚ÄúAccording to the research, the config class was named X, so let‚Äôs fix that in the code‚Äù ‚Äì demonstrating the AI+human collaboration).
ÔÇß (If time permits and it makes sense, demonstrate an edit mode usage: e.g., using VS Code‚Äôs ‚Äúinline suggestions‚Äù or editing a function and asking Copilot to refine it. HVE-CORE supports an Edit Mode that allows the AI to modify selected text safely86 87, which can be mentioned but a live demo might be too much. Possibly skip live edit mode due to complexity.)
ÔÇß After coding, simulate running the app (or at least running tests). Assume tests pass or the feature works (since a live demo of an actual app might be complex; you could show a screenshot of a dark mode toggle working if prepared).
ÔÇß Demo (Review): Now to use the AI for review. Open the pull request or a diff of your changes, and invoke @pr-review: ‚ÄúReview these changes for any issues.‚Äù The AI will output a review ‚Äì e.g., it might point out a potential edge case or just say ‚ÄúLooks good.‚Äù If it finds something (maybe it notices a missing test or a potential null check), mention that‚Äôs a good catch. This underscores that AI can improve quality, not just speed.
ÔÇß Close the demo by confirming the feature was implemented successfully using RPI, and the AI even did a sanity-check in review.
‚Ä¢ Slide 8: ‚ÄúExpanding RPI: Discovery & Design Thinking‚Äù ‚Äì Advanced topic: D-RPI and user-centric design.
o Discovery (Ask Mode) ‚Äì an optional pre-step before Research for unclear problems88. AI assists in exploring requirements, asking clarifying questions.
o Mirrors ‚ÄúDesign Thinking‚Äù stages: helps to empathize with user needs and define the problem before solutioning.
o Context pre-seeding: Keeping Discovery Q&A in the same thread primes the subsequent Research with richer context89.
o Edit Mode + RPI: Another variant where you allow AI to make small safe edits during research (e.g., to experiment or refactor on the fly)90. Useful for complex refactoring tasks.
Speaker notes: Explain that RPI isn‚Äôt a one-size-fits-all; it can be adapted. For example, when requirements are fuzzy, we insert a Discovery phase. That‚Äôs basically a conversation (possibly with the AI) to clarify what the user or customer actually needs. This is analogous to the first stages of Design Thinking ‚Äì understanding the user and framing the problem correctly. By doing this in the same chat session, when we then transition into Research, the AI retains that context ‚Äì we call it ‚Äúcontext pre-seeding‚Äù91. So the AI already knows the high-level intent, which can make the research more effective. Mention that this approach (sometimes called D-RPI) has been helpful when dealing with a completely unfamiliar codebase or when implementing a very open-ended feature ‚Äì it reduces the chance of heading down the wrong path. Also mention Edit Mode as another tweak: in cases where you want to do small experiments safely, HVE‚Äôs Edit Mode allows the AI to suggest changes directly on a selected portion of code, which you can accept or reject. This was an addition to enhance safety when you do need to write code in the middle of research (for instance, to refactor a function for easier modification)92. Tying back to design thinking: the overarching message is that HVE-CORE is evolving to support more creative and ambiguous stages of development, not just well-defined coding tasks.
‚Ä¢ Slide 9: ‚ÄúHVE-CORE for Everyone ‚Äì Roles & Use Cases‚Äù ‚Äì How various team members use HVE-CORE.
o Developers: Use RPI to implement features/bugs efficiently. Less grunt work, more focus on logic. AI handles boilerplate, suggests improvements, ensures consistency (e.g., coding style, commit messages)93 94.
o Technical Leads / Architects: Use Prompt Builder to encode best practices (architecture guidelines, naming conventions) into the AI‚Äôs instructions. Use Researcher/Planner to investigate and plan major refactoring or design changes across a large codebase in minutes rather than days.
o Project/Program Managers: Leverage Researcher to gather info for status updates or to understand technical issues in order to facilitate team discussions. Use Planner to turn big project goals into backlog items or schedules. Automate writing of repetitive project docs or follow-ups using Copilot (even things like meeting notes).
o OSS/New Contributors: Use RPI as a self-service mentor ‚Äì quickly onboard to a new repo by researching documentation and code, then plan and execute a small fix. Ensures adherence to project standards (with AI highlighting the right patterns to follow)95 96.
o Designers/Analysts: In early stages, use Discovery Q&A to explore problem space. Later, use HVE outputs (research summary, plans) to inform design decisions. Possibly use Copilot to generate user stories or analyze user feedback.
Speaker notes: Reinforce that HVE-CORE is a multi-tool that can be wielded by different roles. For developers, it‚Äôs like an ‚ÄúAI pair programmer + assistant‚Äù that takes care of a lot of tedious work (for example, auto-configuring git or writing unit tests boilerplate)97 98. For tech leads, it ensures the team‚Äôs work is aligned (since the AI is following the rules you set, e.g., always use certain design patterns). For project managers, it can even help with producing slides and reports ‚Äì the irony that we are using HVE-CORE to make this very presentation is a case in point! Smile and mention that you ate your own dogfood (or ‚Äúdrank your own champagne‚Äù) by using RPI to build the presentation, which a PM or TPM could also do for their project readouts. By highlighting these use cases, we show that HVE-CORE drives a culture where everyone in the team can be augmented by AI in their respective tasks. This flattens some learning curves and frees up human talent for higher-level thinking.
Slide 10: ‚ÄúReal Results with HVE-CORE‚Äù ‚Äì Case Studies & Metrics
‚Ä¢ 50% faster secure cloud deployments (global telecom adopting AI-driven Infrastructure-as-Code)1
‚Ä¢ 90% faster generation of architecture docs & security plans (days instead of weeks)2
‚Ä¢ Prototype built in 2 days vs. 8 weeks using RPI and Copilot (internal hackathon success)3
‚Ä¢ Improved code quality: AI-powered PR reviews catch issues beyond trivial style fixes (e.g. missing null-checks, potential security holes) before merge4
‚Ä¢ Better developer experience: Less rework and context-switching ‚Üí higher developer satisfaction and more time for innovation5
Speaker notes: These are not just hypothetical gains‚Äîreal teams have seen dramatic improvements with HVE-CORE. For instance, one global telecom rolled out an HVE approach in their cloud deployment process and cut deployment times by 50%6. Another team saw that tasks like writing architecture documents and security plans went from taking several days to just a few hours‚Äîa 90% reduction in time7. At an internal hackathon, using RPI and Copilot, a team delivered a working prototype in only 2 days, something that traditionally would have taken 6‚Äì8 weeks8.
Speed isn‚Äôt the only benefit. Quality has improved too. The AI-driven PR Review agent helped developers catch subtle bugs and security issues before code was merged (like a missing null-check that could‚Äôve caused a production error)9. This early detection prevents expensive rework down the road.
And perhaps most importantly, developers are happier. By eliminating tedious tasks and reducing context-switching, HVE-CORE frees engineers to focus on creative problems. Teams report significantly less frustration and higher morale; developers feel more productive and are able to deliver value without the late-night fire drills and ‚Äúyak shaving‚Äù they used to endure10. In short, HVE-CORE isn‚Äôt just making us faster‚Äîit‚Äôs making our work lives better.

Slide 11: ‚ÄúLearning Resources & Getting Started‚Äù
‚Ä¢ HVE-Learning Repository (GitHub: microsoft/hve-learning): Self-paced modules on prompt engineering, backlog management, RPI methodology, etc., to train both engineers and PMs11 12.
‚Ä¢ Customer Zero Katas (aka.ms/cz-repo-katas): Hands-on exercises to practice HVE-CORE and RPI skills, used for upskilling teams on real-world scenarios13.
‚Ä¢ HVE-CORE VS Code Extension: Install ‚ÄúHVE Essentials (ise-hve-essentials.hve-core)‚Äù from the Visual Studio Marketplace to get all HVE-CORE chat modes and commands in VS Code. Minimal setup: clone the microsoft/hve-core repo and add a 3-line config to your workspace settings to enable HVE-CORE in any project14.
‚Ä¢ HVE-CORE Documentation: Official docs and quick-start guide available at aka.ms/hve-core (covers installation steps, usage examples, and FAQs).
Speaker notes: To help everyone ramp up, we‚Äôve put together several resources:
First, the HVE-Learning repository on GitHub ‚Äì this is your one-stop shop for training materials. It contains modules on things like how to write great prompts, how to manage your backlog with AI, and how to run the RPI cycle. It‚Äôs designed for both technical folks and project managers, so everyone can learn the ropes of hypervelocity engineering at their own pace15.
We also have ‚ÄúCustomer Zero‚Äù Katas ‚Äì think of these as practical exercises or mini-projects to practice HVE methods. They‚Äôre on GitHub (including a handy short link at aka.ms/cz-repo-katas) and are used within Microsoft to train our own teams on HVE-CORE techniques16. These katas cover real scenarios, so you can apply what you learn in a safe sandbox before using it on your actual project.
To start using HVE-CORE in your daily work, the setup is intentionally very simple. Just clone the microsoft/hve-core repository (it‚Äôs an open-source library) into your development environment, and add a tiny snippet ‚Äì literally three lines ‚Äì to your VS Code settings17. Then install the HVE-CORE VS Code extension from the Marketplace (listed as ‚ÄúHVE Essentials‚Äù) and you‚Äôre ready to go. The extension gives you access to all the custom Copilot agents and one-click commands inside VS Code, no complicated configuration needed.
Finally, we have thorough documentation and guides on aka.ms/hve-core. There you‚Äôll find step-by-step instructions, troubleshooting tips, and answers to common questions. These resources ensure you‚Äôre never stuck‚Äîhelp is always available to adopt HVE-CORE successfully.

Slide 12: ‚ÄúCommunity & Contribution‚Äù
‚Ä¢ Join the HVE Community: Participate in bi-weekly HVE Community Syncs for live demos, Q&A, and knowledge sharing18. Follow internal channels like the #Hypervelocity and #SeasonOfHVE Teams tags for updates on new features and events19.
‚Ä¢ Contribute to HVE-CORE & Accelerators: HVE-CORE and its flagship accelerators (Edge AI, Robotics, etc.) are open to contributions ‚Äì everyone can get involved. Look for ‚Äúgood first issue‚Äù tags on GitHub to start contributing code, prompts, or documentation20.
‚Ä¢ Share Feedback & Success Stories: Use GitHub Issues to report bugs or suggest improvements. Your experiences (e.g. what worked, what was challenging) are incredibly valuable ‚Äì they help us improve HVE-CORE for everyone. We encourage you to present your HVE success stories at community calls or Guild forums.
Speaker notes: We invite you to become part of the growing HVE community. There‚Äôs a whole network of practitioners and enthusiasts eager to share tips and learn from each other. Every two weeks, we host an HVE Community Sync ‚Äì an open call where teams present demos, discuss new developments, and answer questions. It‚Äôs a great way to see how others are using HVE-CORE and to get help directly from experts21. We also have internal discussion channels (search for ‚ÄúHypervelocity‚Äù or ‚ÄúSeasonOfHVE‚Äù on Teams) where you can ask questions any time, or just lurk and learn from the discussions22.
HVE-CORE itself, along with related solution accelerators like Edge-AI and the Robotics Reference Architecture, are open-source projects on GitHub. This means if you spot a bug or have an idea, you can contribute directly! We welcome contributions ‚Äì in fact, newbies are encouraged to look for issues labeled ‚Äúgood first issue‚Äù in our repos to find beginner-friendly tasks23. It could be anything from writing a new prompt to improving documentation or adding a small feature. Contributing not only helps you deepen your understanding, but also benefits the entire community.
Finally, we love hearing about your experiences. If you‚Äôve tried HVE-CORE, let us know how it went. Maybe you shaved a 2-week task down to 2 days, or maybe you encountered a tricky part that we can improve. Share your feedback via GitHub or in our community calls. This collective learning is what makes HVE-CORE better with each iteration. The more people get involved ‚Äì whether by contributing code or just telling us what worked ‚Äì the faster we all move.

Slide 13: ‚ÄúKey Takeaways & Next Steps‚Äù
‚Ä¢ HVE-CORE = accelerate delivery and quality: By combining AI tools with structured practices, teams deliver solutions significantly faster (tasks up to 88% quicker24) without sacrificing quality or security.
‚Ä¢ RPI is a game-changer: The Research ‚Üí Plan ‚Üí Implement cycle is the ‚Äúsecret sauce‚Äù that turns Copilot from a nifty helper into a reliable partner, eliminating guesswork and preventing the costly ‚Äúcode-and-rework‚Äù loop (structured phases = no more AI sprawl).
‚Ä¢ Empower every role: HVE-CORE‚Äôs approach isn‚Äôt just for coders. PMs, TPMs, and others can leverage it to improve planning, documentation, and cross-team collaboration, creating a shared rhythm and language for projects.
‚Ä¢ Start your hypervelocity journey: It only takes a few minutes to set up HVE-CORE25. Pick a small upcoming task or bug and run it through RPI with Copilot ‚Äì see the difference yourself. Then join our community to multiply that impact by learning from colleagues and contributing back.
Speaker notes: To wrap up: Hypervelocity Engineering is about making our whole team dramatically faster and better. With HVE-CORE, we have a proven toolkit that‚Äôs already delivering results ‚Äì some teams have seen nearly a two-fold increase in speed, while also catching issues that could have slipped through before26 27.
The RPI framework is the heart of this approach. It might feel counterintuitive at first to slow down and do a separate research and planning step, but that structure is exactly what unlocks the speed later. By forcing ourselves (and the AI) to ‚Äúthink before coding,‚Äù we avoid the painful cycle of writing code and then reworking it over and over. Our motto from the field is: ‚ÄúStructured phases kill the AI rework loop.‚Äù When Copilot knows it can‚Äôt jump straight to writing code, it focuses on finding the truth instead of just producing something that ‚Äúlooks right.‚Äù
Remember that HVE-CORE isn‚Äôt just for developers. It‚Äôs a toolkit for everyone on the team. If you‚Äôre a PM or TPM, you might use it to auto-generate backlog items or status reports. If you‚Äôre an architect, you can use it to draft design docs or do impact analysis. It creates a common workflow where all roles can collaborate with AI and with each other more effectively.
Our call to action for you: try HVE-CORE on one of your projects. The setup is trivial ‚Äì clone the repo, add a few config lines, and you‚Äôre off28. Start with something manageable, experience RPI in practice, and measure the results. We think you‚Äôll be pleasantly surprised. And don‚Äôt do it alone ‚Äì plug into the community, ask questions, and share your wins. Hypervelocity Engineering is a journey, and we‚Äôre all still learning. But one thing is clear: this is a transformative way of working. By embracing HVE-CORE and RPI, you‚Äôre not just speeding up projects ‚Äì you‚Äôre freeing up your team‚Äôs creativity and time to focus on what really matters. That‚Äôs the future of engineering at Microsoft.
Thank you for your time ‚Äì let‚Äôs go forth and build at hypervelocity! Now I‚Äôll open it up for any questions.
